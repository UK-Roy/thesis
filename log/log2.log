2024-02-13 13:42:54,500 - INFO - ['As an example, you can use a reward function like this one:\n\ndef reward_function(object_pos: torch.Tensor, goal_pos: torch.Tensor) -> Tuple[torch.Tensor, Dict[str, torch.Tensor]]:\n    # distance between the agent and the goal\n    distance = distance(object_pos, goal_pos)\n    # reward = 1 if distance < 0.1 else 0\n    reward = 1 - (distance / 0.1)\n    return reward, {\n        "distance": distance\n    }\n\nThis reward function gives a reward of 1 if the agent is closer than 0.1 to the goal, and 0 otherwise. The "distance" variable is used to compute the reward.\n\nNote that this is just an example, you may want to adjust the parameters (distance_threshold, object_size, goal_xy_range, etc) to suit your specific problem. Also, you may want to use other types of distance metrics (e.g. Euclidean distance, Manhattan distance, etc) depending on the problem.\n\nAlso, you can use other types of reward functions such as:\n\n* Sparse reward: reward = 1 if the agent is closer than a certain distance to the goal, and 0 otherwise.\n* Asynchronous reward: reward = 1 if the agent is closer than a certain distance to the goal, and 0 otherwise.\n* Temporal reward: reward = 1 if the agent is closer than a certain distance to the goal after a certain amount of time, and 0 otherwise.\n* Hierarchical reward: reward = 1 if the agent is closer than a certain distance to the goal, and 0 otherwise, but with different levels of rewards for different distances.\n\nPlease let me know if you have any questions or if you need more help.']
